{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Fine-Tuning BERT for Spam Classification.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataubc/Natural-Language-Processing-and-Computational-Linguistics/blob/master/Copy_of_Fine_Tuning_BERT_for_Spam_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# Install Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hkhc10wNrGt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1040ef9b-d43d-493e-9383-8ae3a290532b"
      },
      "source": [
        "!pip install transformers~=2.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers~=2.1 in /usr/local/lib/python3.6/dist-packages (2.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (0.1.94)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (20.7)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (0.7.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers~=2.1) (0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=2.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=2.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=2.1) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=2.1) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers~=2.1) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=2.1) (0.17.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=2.1) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=2.1) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwJrQFQgN_BE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb368a62-55ab-482c-932e-1df53d697d5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzPPOrVQWiW5"
      },
      "source": [
        "df = pd.read_csv('/content/gdrive/MyDrive/sentiment_dataset_train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buPYrlBy0h_F",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "99c0bf1a-5000-4e67-801f-6f9d72e12404"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Arrived about 10pm and check in was painless. ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I checked in at 4pm even tough room was not re...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I chose this hotel, as it was in a good locati...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Great location, super close to shops &amp; a 10min...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I was in the Sir Adam Hotel to visit a friend....</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                             review rating\n",
              "0   0  Arrived about 10pm and check in was painless. ...      4\n",
              "1   1  I checked in at 4pm even tough room was not re...      2\n",
              "2   2  I chose this hotel, as it was in a good locati...      2\n",
              "3   3  Great location, super close to shops & a 10min...      4\n",
              "4   4  I was in the Sir Adam Hotel to visit a friend....      3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OMMmB2u0mH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "f86f6372-e808-4a52-f4be-3e8366817086"
      },
      "source": [
        "df.columns = ['id','text','label']\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Arrived about 10pm and check in was painless. ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I checked in at 4pm even tough room was not re...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>I chose this hotel, as it was in a good locati...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Great location, super close to shops &amp; a 10min...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>I was in the Sir Adam Hotel to visit a friend....</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35000</th>\n",
              "      <td>35000</td>\n",
              "      <td>Paris is always welcome city, but this time th...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35001</th>\n",
              "      <td>35001</td>\n",
              "      <td>Beautiful place very clean and welcoming irini...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35002</th>\n",
              "      <td>35002</td>\n",
              "      <td>The hotel is ok considering the price we paid....</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35003</th>\n",
              "      <td>35003</td>\n",
              "      <td>First your stuck if you miss last tram at midn...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35004</th>\n",
              "      <td>35004</td>\n",
              "      <td>The staff was very nice. The room was fine - n...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35005 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id                                               text label\n",
              "0          0  Arrived about 10pm and check in was painless. ...     4\n",
              "1          1  I checked in at 4pm even tough room was not re...     2\n",
              "2          2  I chose this hotel, as it was in a good locati...     2\n",
              "3          3  Great location, super close to shops & a 10min...     4\n",
              "4          4  I was in the Sir Adam Hotel to visit a friend....     3\n",
              "...      ...                                                ...   ...\n",
              "35000  35000  Paris is always welcome city, but this time th...     5\n",
              "35001  35001  Beautiful place very clean and welcoming irini...     3\n",
              "35002  35002  The hotel is ok considering the price we paid....     3\n",
              "35003  35003  First your stuck if you miss last tram at midn...     3\n",
              "35004  35004  The staff was very nice. The room was fine - n...     3\n",
              "\n",
              "[35005 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676DPU1BOPdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8b3ed6-807e-4019-f918-eb78ed34f54a"
      },
      "source": [
        "# check class distribution\n",
        "df['label'].value_counts(normalize = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2                                                0.200857\n",
              "1                                                0.200771\n",
              "4                                                0.199886\n",
              "5                                                0.199314\n",
              "3                                                0.199143\n",
              "Tables not made up prior to guest seating. 2.    0.000029\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkKG_sIv2GsJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0iO1RxG0lQ5"
      },
      "source": [
        "df = df[df['label'] != 'Tables not made up prior to guest seating. 2.']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Pq7tbH1wjn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OczsIQE2Nsx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aee83b10-0314-49a6-fb74-cf54642f8233"
      },
      "source": [
        "df['label'] = df['label'].astype(int) -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH35eEp22AMr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fa6df4c-8452-4aee-eb3b-3f435edb8a88"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id        int64\n",
              "text     object\n",
              "label     int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "source": [
        "train_text, val_text, train_labels, val_labels = train_test_split(df['text'], df['label'], \n",
        "                                                                    random_state=2020, \n",
        "                                                                    test_size=0.3, \n",
        "                                                                    stratify=df['label'])\n",
        "\n",
        "df_dev = pd.read_csv('/content/gdrive/MyDrive/sentiment_dataset_dev.csv')\n",
        "\n",
        "\n",
        "test_text = df_dev['review']\n",
        "df_dev['rating']= df_dev['rating'].astype(int) -1 \n",
        "test_labels = df_dev['rating']\n",
        "# we will use temp_text and temp_labels to create validation and test set\n",
        "#val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                #random_state=2018, \n",
        "                                                                #test_size=0.5, \n",
        "                                                                #stratify=temp_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBAGLIe48qep",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "af803728-9860-4d66-de32-213ceee55c6e"
      },
      "source": [
        "df_dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>The hotel position is very good, center of the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Not a very big room but very comfortable and c...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>The hotel is located near Kurfürstendamm in a ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>My booking was for 2 rooms and I have made the...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Excellent hotel, fantastic swimming pool, very...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7494</th>\n",
              "      <td>7494</td>\n",
              "      <td>we stayed here earlier this month with another...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7495</th>\n",
              "      <td>7495</td>\n",
              "      <td>We stayed 3 nights at this hotel.   The staff ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7496</th>\n",
              "      <td>7496</td>\n",
              "      <td>Our first night here, a large group of Guests ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7497</th>\n",
              "      <td>7497</td>\n",
              "      <td>Arrived here on Thursday 14th with 5 other peo...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7498</th>\n",
              "      <td>7498</td>\n",
              "      <td>I had a wonderful 5 night stay at the Hotel l'...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7499 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                             review  rating\n",
              "0        0  The hotel position is very good, center of the...       1\n",
              "1        1  Not a very big room but very comfortable and c...       3\n",
              "2        2  The hotel is located near Kurfürstendamm in a ...       3\n",
              "3        3  My booking was for 2 rooms and I have made the...       1\n",
              "4        4  Excellent hotel, fantastic swimming pool, very...       4\n",
              "...    ...                                                ...     ...\n",
              "7494  7494  we stayed here earlier this month with another...       4\n",
              "7495  7495  We stayed 3 nights at this hotel.   The staff ...       2\n",
              "7496  7496  Our first night here, a large group of Guests ...       1\n",
              "7497  7497  Arrived here on Thursday 14th with 5 other peo...       2\n",
              "7498  7498  I had a wonderful 5 night stay at the Hotel l'...       4\n",
              "\n",
              "[7499 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1kY3gZjO2RE"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAH73n39PHLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "578b37f9-c9c0-4536-9637-96086537e269"
      },
      "source": [
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKwbpeN_PMiu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "feb55b76-4f8c-4b18-fab3-89555bdfbe55"
      },
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef0c336d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "source": [
        "max_seq_len = 170"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk5S7DWaP2t6"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 8\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      #self.fc2 = nn.Linear(512,512)\n",
        "\n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc3 = nn.Linear(512,5)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      #x = self.fc2(x)\n",
        "\n",
        "      #x = self.relu(x)\n",
        "\n",
        "      #x = self.dropout(x)\n",
        "\n",
        "      x = self.fc3(x)\n",
        "\n",
        "\n",
        "  \n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taXS0IilRn9J"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izY5xH5eR7Ur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3e28f9-9858-478e-e84e-c2233c02d84c"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.99621874 0.99581386 1.00418033 1.00049    1.0033579 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mlv1XmAQ4IfQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      #elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1USGTntS3TS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa9199a7-188a-4651-f33a-fdf7f91321d5"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 1\n",
            "  Batch    50  of  3,063.\n",
            "  Batch   100  of  3,063.\n",
            "  Batch   150  of  3,063.\n",
            "  Batch   200  of  3,063.\n",
            "  Batch   250  of  3,063.\n",
            "  Batch   300  of  3,063.\n",
            "  Batch   350  of  3,063.\n",
            "  Batch   400  of  3,063.\n",
            "  Batch   450  of  3,063.\n",
            "  Batch   500  of  3,063.\n",
            "  Batch   550  of  3,063.\n",
            "  Batch   600  of  3,063.\n",
            "  Batch   650  of  3,063.\n",
            "  Batch   700  of  3,063.\n",
            "  Batch   750  of  3,063.\n",
            "  Batch   800  of  3,063.\n",
            "  Batch   850  of  3,063.\n",
            "  Batch   900  of  3,063.\n",
            "  Batch   950  of  3,063.\n",
            "  Batch 1,000  of  3,063.\n",
            "  Batch 1,050  of  3,063.\n",
            "  Batch 1,100  of  3,063.\n",
            "  Batch 1,150  of  3,063.\n",
            "  Batch 1,200  of  3,063.\n",
            "  Batch 1,250  of  3,063.\n",
            "  Batch 1,300  of  3,063.\n",
            "  Batch 1,350  of  3,063.\n",
            "  Batch 1,400  of  3,063.\n",
            "  Batch 1,450  of  3,063.\n",
            "  Batch 1,500  of  3,063.\n",
            "  Batch 1,550  of  3,063.\n",
            "  Batch 1,600  of  3,063.\n",
            "  Batch 1,650  of  3,063.\n",
            "  Batch 1,700  of  3,063.\n",
            "  Batch 1,750  of  3,063.\n",
            "  Batch 1,800  of  3,063.\n",
            "  Batch 1,850  of  3,063.\n",
            "  Batch 1,900  of  3,063.\n",
            "  Batch 1,950  of  3,063.\n",
            "  Batch 2,000  of  3,063.\n",
            "  Batch 2,050  of  3,063.\n",
            "  Batch 2,100  of  3,063.\n",
            "  Batch 2,150  of  3,063.\n",
            "  Batch 2,200  of  3,063.\n",
            "  Batch 2,250  of  3,063.\n",
            "  Batch 2,300  of  3,063.\n",
            "  Batch 2,350  of  3,063.\n",
            "  Batch 2,400  of  3,063.\n",
            "  Batch 2,450  of  3,063.\n",
            "  Batch 2,500  of  3,063.\n",
            "  Batch 2,550  of  3,063.\n",
            "  Batch 2,600  of  3,063.\n",
            "  Batch 2,650  of  3,063.\n",
            "  Batch 2,700  of  3,063.\n",
            "  Batch 2,750  of  3,063.\n",
            "  Batch 2,800  of  3,063.\n",
            "  Batch 2,850  of  3,063.\n",
            "  Batch 2,900  of  3,063.\n",
            "  Batch 2,950  of  3,063.\n",
            "  Batch 3,000  of  3,063.\n",
            "  Batch 3,050  of  3,063.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of  1,313.\n",
            "  Batch   100  of  1,313.\n",
            "  Batch   150  of  1,313.\n",
            "  Batch   200  of  1,313.\n",
            "  Batch   250  of  1,313.\n",
            "  Batch   300  of  1,313.\n",
            "  Batch   350  of  1,313.\n",
            "  Batch   400  of  1,313.\n",
            "  Batch   450  of  1,313.\n",
            "  Batch   500  of  1,313.\n",
            "  Batch   550  of  1,313.\n",
            "  Batch   600  of  1,313.\n",
            "  Batch   650  of  1,313.\n",
            "  Batch   700  of  1,313.\n",
            "  Batch   750  of  1,313.\n",
            "  Batch   800  of  1,313.\n",
            "  Batch   850  of  1,313.\n",
            "  Batch   900  of  1,313.\n",
            "  Batch   950  of  1,313.\n",
            "  Batch 1,000  of  1,313.\n",
            "  Batch 1,050  of  1,313.\n",
            "  Batch 1,100  of  1,313.\n",
            "  Batch 1,150  of  1,313.\n",
            "  Batch 1,200  of  1,313.\n",
            "  Batch 1,250  of  1,313.\n",
            "  Batch 1,300  of  1,313.\n",
            "\n",
            "Training Loss: 1.216\n",
            "Validation Loss: 1.034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OacxUyizS8d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8695b98-7a26-45cb-8d7a-cb283da92c12"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZl0SZmFTRQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "e085b412-1b4c-41f2-d488-e2c2c4cde8fe"
      },
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-3a253e0de617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-703720e2ca55>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sent_id, mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m       \u001b[0;31m#pass the inputs to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         )\n\u001b[1;32m    729\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.65 GiB (GPU 0; 14.73 GiB total capacity; 11.39 GiB already allocated; 2.24 GiB free; 11.45 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ms1ObHZxTYSI"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqzLS7rHTp4T"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpX1uTwjUPY6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}